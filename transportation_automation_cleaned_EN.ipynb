{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffacf317",
   "metadata": {},
   "source": [
    "# TransLuxPop — Transportation Feature Extraction Pipeline (OSMnx)\n",
    "This notebook is a cleaned and reproducible version of `transportation_automation.ipynb`:\n",
    "- Deduplicated imports and settings\n",
    "- Centralized configuration (paths, Overpass endpoints, parameters)\n",
    "- Refactored core logic into reusable functions\n",
    "- Added checkpointing (resume) and failure retries\n",
    "\n",
    "> Tip: export these functions into scripts under `code/` for a fully reproducible GitHub release.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68c4b1",
   "metadata": {},
   "source": [
    "## 0. Environment & Dependencies\n",
    "建议版本：\n",
    "- osmnx >= 1.8（或 2.x，代码做兼容）\n",
    "- geopandas, shapely, networkx\n",
    "- pandas, numpy, tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6940c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Imports =====\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "# Optional: silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a3dc1",
   "metadata": {},
   "source": [
    "## 1. Global Configuration (edit here only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54363e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Config =====\n",
    "OVERPASS_URLS = [\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    # 备用源（可按需要添加）\n",
    "    # \"https://overpass-api.de/api/interpreter\",\n",
    "]\n",
    "\n",
    "# 输入：你的 grid 列表（Excel/CSV）\n",
    "GRID_XLSX_PATH = \"PATH/TO/grids_set_3_HQ.xlsx\"\n",
    "\n",
    "# 输出：写回的 dataset（建议写到本地 data/ 目录）\n",
    "OUTPUT_XLSX_PATH = \"PATH/TO/grids_set_3_with_trans.xlsx\"\n",
    "\n",
    "# checkpoint：每 N 个 grid 保存一次，防止中途崩掉\n",
    "CHECKPOINT_EVERY = 10\n",
    "\n",
    "# OSMnx 设置\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a139e4e",
   "metadata": {},
   "source": [
    "## 2. Utilities: OSMnx compatibility + retries + projected length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_overpass(url: str):\n",
    "    ox.settings.overpass_url = url\n",
    "\n",
    "def _graph_from_bbox_compat(north, south, east, west, **kwargs):\n",
    "    \"\"\"兼容 osmnx 1.x / 2.x 的 bbox 抓取接口\"\"\"\n",
    "    try:\n",
    "        # osmnx 2.x\n",
    "        return ox.graph.graph_from_bbox(north, south, east, west, **kwargs)\n",
    "    except Exception:\n",
    "        # osmnx 1.x\n",
    "        return ox.graph_from_bbox(north=north, south=south, east=east, west=west, **kwargs)\n",
    "\n",
    "def fetch_graph_with_retry(north, south, east, west, network_type=\"drive\", simplify=True,\n",
    "                           truncate_by_edge=True, max_retry=3, sleep_s=2):\n",
    "    \"\"\"抓取 OSM graph：自动切 overpass + 重试\"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(max_retry):\n",
    "        url = OVERPASS_URLS[attempt % len(OVERPASS_URLS)]\n",
    "        set_overpass(url)\n",
    "        try:\n",
    "            G = _graph_from_bbox_compat(\n",
    "                north, south, east, west,\n",
    "                network_type=network_type,\n",
    "                simplify=simplify,\n",
    "                truncate_by_edge=truncate_by_edge\n",
    "            )\n",
    "            return G\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(sleep_s * (attempt + 1))\n",
    "    raise last_err\n",
    "\n",
    "def project_and_get_edges(G):\n",
    "    \"\"\"投影到米制坐标并返回 edges GeoDataFrame（用于精确长度）\"\"\"\n",
    "    Gp = ox.project_graph(G)\n",
    "    edges = ox.graph_to_gdfs(Gp, nodes=False, edges=True, fill_edge_geometry=True)\n",
    "    if \"geometry\" in edges.columns:\n",
    "        edges[\"length_m\"] = edges.geometry.length\n",
    "    else:\n",
    "        # fallback\n",
    "        edges[\"length_m\"] = edges.get(\"length\", np.nan)\n",
    "    return edges\n",
    "\n",
    "def highway_len_km(edges, hw_types):\n",
    "    \"\"\"统计指定 highway 类型的长度（km）\"\"\"\n",
    "    if edges.empty:\n",
    "        return 0.0\n",
    "    if \"highway\" not in edges.columns:\n",
    "        return 0.0\n",
    "    # highway 字段有时是 list\n",
    "    hw = edges[\"highway\"].apply(lambda x: x[0] if isinstance(x, list) and len(x) else x)\n",
    "    mask = hw.isin(hw_types)\n",
    "    return float(edges.loc[mask, \"length_m\"].sum() / 1000.0)\n",
    "\n",
    "def compute_intersections(G):\n",
    "    \"\"\"用 consolidate_intersections 统计交叉口数量（更稳）\"\"\"\n",
    "    # consolidate 需要有几何\n",
    "    Gp = ox.project_graph(G)\n",
    "    # 注意：consolidate_intersections 对 directed graph 更友好\n",
    "    Gc = ox.simplification.consolidate_intersections(Gp, tolerance=15, rebuild_graph=True, dead_ends=False)\n",
    "    return int(len(Gc.nodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3879d0",
   "metadata": {},
   "source": [
    "## 3. Per-grid transportation feature computation (core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b401378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你可按论文/数据集定义调整 highway 分类\n",
    "HW_MOT = [\"motorway\"]\n",
    "HW_TRU = [\"trunk\"]\n",
    "HW_PRI = [\"primary\"]\n",
    "HW_SEC = [\"secondary\"]\n",
    "HW_TER = [\"tertiary\"]\n",
    "\n",
    "# 城市道路（你定义的 urban）\n",
    "HW_URB = [\"residential\", \"unclassified\", \"service\", \"living_street\"]\n",
    "\n",
    "def compute_transport_features(lat_min, lon_min, lat_max, lon_max):\n",
    "    \"\"\"返回一个 dict：len_mot_km, len_pri_km, ..., intersec_count 等\"\"\"\n",
    "    north, south, east, west = lat_max, lat_min, lon_max, lon_min\n",
    "\n",
    "    G = fetch_graph_with_retry(north, south, east, west)\n",
    "    if G is None or len(G.nodes) == 0:\n",
    "        return {\n",
    "            \"intersec\": 0,\n",
    "            \"len_mot_km\": 0.0, \"len_tru_km\": 0.0, \"len_pri_km\": 0.0,\n",
    "            \"len_sec_km\": 0.0, \"len_ter_km\": 0.0, \"len_urb_km\": 0.0\n",
    "        }\n",
    "\n",
    "    edges = project_and_get_edges(G)\n",
    "\n",
    "    feat = {}\n",
    "    feat[\"intersec\"] = compute_intersections(G)\n",
    "    feat[\"len_mot_km\"] = highway_len_km(edges, HW_MOT)\n",
    "    feat[\"len_tru_km\"] = highway_len_km(edges, HW_TRU)\n",
    "    feat[\"len_pri_km\"] = highway_len_km(edges, HW_PRI)\n",
    "    feat[\"len_sec_km\"] = highway_len_km(edges, HW_SEC)\n",
    "    feat[\"len_ter_km\"] = highway_len_km(edges, HW_TER)\n",
    "    feat[\"len_urb_km\"] = highway_len_km(edges, HW_URB)\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ebc99e",
   "metadata": {},
   "source": [
    "## 4. Batch processing (with checkpoint & resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd06243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(GRID_XLSX_PATH)\n",
    "\n",
    "# 你需要保证表中有这些列名（必要时在这里 rename）\n",
    "required_cols = [\"lat_min\", \"lon_min\", \"lat_max\", \"lon_max\"]\n",
    "for c in required_cols:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing column: {c}\")\n",
    "\n",
    "# 初始化输出列（若不存在）\n",
    "out_cols = [\"intersec\", \"len_mot_km\", \"len_tru_km\", \"len_pri_km\", \"len_sec_km\", \"len_ter_km\", \"len_urb_km\"]\n",
    "for c in out_cols:\n",
    "    if c not in df.columns:\n",
    "        df[c] = np.nan\n",
    "\n",
    "# 如果要断点续跑：只跑缺失的行\n",
    "todo_idx = df.index[df[\"intersec\"].isna()].tolist()\n",
    "print(f\"Total rows: {len(df)}, to compute: {len(todo_idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf45a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, idx in enumerate(tqdm(todo_idx)):\n",
    "    row = df.loc[idx]\n",
    "    try:\n",
    "        feat = compute_transport_features(row.lat_min, row.lon_min, row.lat_max, row.lon_max)\n",
    "        for k, v in feat.items():\n",
    "            # 对齐列名\n",
    "            if k == \"intersec\":\n",
    "                df.at[idx, \"intersec\"] = v\n",
    "            else:\n",
    "                df.at[idx, k] = v\n",
    "    except Exception as e:\n",
    "        # 标记失败（也可以写入 error log）\n",
    "        df.at[idx, \"intersec\"] = -1\n",
    "        # 你也可以把 error 信息写到单独一列\n",
    "        # df.at[idx, \"error_msg\"] = str(e)[:200]\n",
    "\n",
    "    if (j + 1) % CHECKPOINT_EVERY == 0:\n",
    "        df.to_excel(OUTPUT_XLSX_PATH, index=False)\n",
    "\n",
    "# 最终保存\n",
    "df.to_excel(OUTPUT_XLSX_PATH, index=False)\n",
    "print(\"Saved:\", OUTPUT_XLSX_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb4f6d",
   "metadata": {},
   "source": [
    "## 5. Optional: generate normalized *_use features (for cross-country generalization)\n",
    "Your table already uses the *_use idea; here is a standard approach:\n",
    "- Normalize by cell_area (or bbox area)\n",
    "- Or normalize by total road length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"cell_area_km2\" in df.columns:\n",
    "    eps = 1e-6\n",
    "    df[\"Intersec_use\"] = df[\"intersec\"] / (df[\"cell_area_km2\"] + eps)\n",
    "    for hw in [\"mot\",\"tru\",\"pri\",\"sec\",\"ter\",\"urb\"]:\n",
    "        df[f\"{hw}_use\"] = df[f\"len_{hw}_km\"] / (df[\"cell_area_km2\"] + eps)\n",
    "\n",
    "    df.to_excel(OUTPUT_XLSX_PATH, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
